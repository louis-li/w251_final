{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 7, 7, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 13)                26637     \n",
      "=================================================================\n",
      "Total params: 20,888,117\n",
      "Trainable params: 20,833,589\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.Xception(\n",
    "    weights='imagenet',\n",
    "    input_shape=(image_size, image_size, 3),\n",
    "    include_top=False)\n",
    "\n",
    "# Create new model on top.\n",
    "inputs = keras.Input(shape=(image_size, image_size, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = keras.layers.Dense(13)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model('models/Xception_94.17.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: xception/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('xception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"xception\") # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('xception.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data\n",
    "val_x = pd.read_csv('val.zip')\n",
    "val_y = pd.read_csv('val_labels.zip')\n",
    "\n",
    "x_val = np.array(val_x)[:,1:].reshape((val_x.shape[0],image_size,image_size,3))[...,::-1].astype('uint8')\n",
    "y_val = np.array(val_y.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====TF Model result346====\n",
      "[[-17.901442  -23.404106  -32.070164  -14.11898   -21.601423   -1.850947\n",
      "   24.419962   -4.4148817  -2.6606011   9.388392  -36.647743  -12.99203\n",
      "  -11.208064 ]]\n",
      "6\n",
      "====TFLite result====\n",
      "[[-4.1809664   2.3012254  -2.916342    5.5937896  -1.2589072   5.38928\n",
      "   9.906274    8.962482    6.942103    3.748101    0.47662482 10.412812\n",
      "  -0.5057837 ]]\n",
      "11\n",
      "====TF Model result65====\n",
      "[[  3.914014   -5.747334   13.94556    -4.4586163  -8.754163  -10.760125\n",
      "    3.21997     7.268593   -1.9283341   5.1792164   3.2062905   5.978146\n",
      "   -4.1129036]]\n",
      "2\n",
      "====TFLite result====\n",
      "[[ 0.12046222 -0.25927347 10.88987    -0.72205186 -2.940135   -6.352611\n",
      "   5.2650185   5.7163672   0.27584827  3.8899827   2.6346333   4.300824\n",
      "  -2.6199255 ]]\n",
      "2\n",
      "====TF Model result76====\n",
      "[[  0.58516854   0.23161644  18.535362    -5.8178697  -10.962278\n",
      "  -12.415214     8.200231    10.053365    -5.309121     4.216158\n",
      "   -1.4761102    3.3084779   -5.2805204 ]]\n",
      "2\n",
      "====TFLite result====\n",
      "[[-1.40600335e-02 -2.82122207e+00  1.75482769e+01 -3.59187770e+00\n",
      "  -3.43836379e+00 -1.00965948e+01  8.17093563e+00  8.32967949e+00\n",
      "   6.62942052e-01  8.24118137e+00  1.50981534e+00  6.96646929e+00\n",
      "  -5.96249342e+00]]\n",
      "2\n",
      "====TF Model result243====\n",
      "[[-10.138395     8.549107   -24.455757   -21.970783   -33.789463\n",
      "  -33.05155     -5.703699     0.30210832 -15.696805   -26.429276\n",
      "   20.423874   -12.295424   -39.5711    ]]\n",
      "10\n",
      "====TFLite result====\n",
      "[[ 1.9813216   8.389012   -1.9807453  -3.0695894  -0.59353113 -5.7724414\n",
      "   5.7792296   9.838902    2.6446073   0.4016126  16.374119    4.7104807\n",
      "  -4.844022  ]]\n",
      "10\n",
      "====TF Model result69====\n",
      "[[  2.8371341   -3.1916225   11.8921995    1.0604776   -6.4914036\n",
      "  -10.8707       0.19823605   6.0021157   -1.2174249    2.5806928\n",
      "    3.3204937    1.835965    -3.3973823 ]]\n",
      "2\n",
      "====TFLite result====\n",
      "[[-1.8332978e-01 -1.4718783e-01  1.0117836e+01  3.6595576e-03\n",
      "  -2.8979545e+00 -5.7470393e+00  5.7441368e+00  5.7558169e+00\n",
      "   8.7384868e-01  3.6376443e+00  2.8527744e+00  4.5423012e+00\n",
      "  -3.1935015e+00]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    index = np.random.randint(360)\n",
    "    print(f\"====TF Model result{index}====\")\n",
    "    print(model.predict(np.expand_dims(x_val[index],axis=0)))\n",
    "    print(y_val[index])\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_path=\"InceptionResNetV2.tflite\")\n",
    "    interpreter.allocate_tensors()\n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    # Test the model on random input data.\n",
    "    input_shape = input_details[0]['shape']\n",
    "\n",
    "    img = cv2.resize(x_val[index], (image_size,image_size)).astype('float32')\n",
    "\n",
    "    input_data = np.expand_dims(img, axis = 0)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # The function `get_tensor()` returns a copy of the tensor data.\n",
    "    # Use `tensor()` in order to get a pointer to the tensor.\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    print(\"====TFLite result====\")\n",
    "    print(output_data)\n",
    "    print(np.argmax(output_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 331, 331, 3)]     0         \n",
      "_________________________________________________________________\n",
      "NASNet (Model)               (None, 11, 11, 4032)      84916818  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 4032)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 13)                52429     \n",
      "=================================================================\n",
      "Total params: 84,969,247\n",
      "Trainable params: 84,772,579\n",
      "Non-trainable params: 196,668\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: NASNetLarge/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: NASNetLarge/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====TF Model result324====\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 331, 331, 3) for input Tensor(\"input_2_1:0\", shape=(None, 331, 331, 3), dtype=float32), but it was called on an input with incompatible shape (None, 224, 224, 3).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 331, 331, 3) for input Tensor(\"input_2_1:0\", shape=(None, 331, 331, 3), dtype=float32), but it was called on an input with incompatible shape (None, 224, 224, 3).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 331, 331, 3) for input Tensor(\"input_1_1:0\", shape=(None, 331, 331, 3), dtype=float32), but it was called on an input with incompatible shape (None, 224, 224, 3).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 331, 331, 3) for input Tensor(\"input_1_1:0\", shape=(None, 331, 331, 3), dtype=float32), but it was called on an input with incompatible shape (None, 224, 224, 3).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -8.5282135 -19.363518  -16.52757   -11.873962   -5.7922344  -8.415912\n",
      "   23.99141    -2.5310426   5.828314    1.085365  -12.8724375  -3.8069303\n",
      "  -15.421123 ]]\n",
      "6\n",
      "====TFLite result====\n",
      "[[-1.3825101  1.6070299 -0.1115901 -1.5724983  1.0438304  5.835176\n",
      "  23.378407   7.1895914 14.445209   8.269168   5.057511   2.975391\n",
      "  -2.8058362]]\n",
      "6\n",
      "====TF Model result245====\n",
      "[[ -3.629729    -0.9774473   -7.341594    -0.22208425 -11.239543\n",
      "   -9.283462     0.11140212   1.7786671   -4.116989    -3.5408378\n",
      "    9.306289    -1.1097876  -10.166046  ]]\n",
      "10\n",
      "====TFLite result====\n",
      "[[ 0.7998347 10.453156  -1.2456601 -5.1298923 -1.3739543 -6.4387946\n",
      "  11.405606  10.661482   2.9767356  4.238061  21.551626   6.246598\n",
      "  -7.3708577]]\n",
      "10\n",
      "====TF Model result215====\n",
      "[[ -1.3384378  -1.2458938  -6.145743    2.2396846 -10.531468   -9.579082\n",
      "   -1.8510113   1.5018973  -2.8273437  -4.362086   10.495873    0.3627963\n",
      "   -9.966937 ]]\n",
      "10\n",
      "====TFLite result====\n",
      "[[ 2.999232    6.6426644  -1.3552171   0.898814   -1.710811   -4.7169\n",
      "   0.08842207  5.1538467   2.8415096  -1.3402768  13.89454     4.1969967\n",
      "  -3.872591  ]]\n",
      "10\n",
      "====TF Model result309====\n",
      "[[ -6.557088     8.767151    -7.3461366   -4.0578737  -10.694651\n",
      "  -12.726784    -2.6989768    0.44346258  -4.3039713    0.01542173\n",
      "   -1.2228256   -4.370693    -8.798435  ]]\n",
      "1\n",
      "====TFLite result====\n",
      "[[-2.141429   11.205537   -0.92738885  3.1983795   0.1624501  -1.8415712\n",
      "   1.0913941   1.7293258   1.1946235   0.30960694  8.502022    3.769101\n",
      "  -2.4065003 ]]\n",
      "1\n",
      "====TF Model result343====\n",
      "[[ -8.227852   -11.260021   -12.014203    -8.425589   -10.346108\n",
      "   -6.9595914   15.4782715   -4.3331904    0.8684846   -0.04838325\n",
      "  -11.632402     0.46894848 -15.23927   ]]\n",
      "6\n",
      "====TFLite result====\n",
      "[[-1.3346812   4.001396   -2.0354857   0.88905805 -0.95524037  6.764582\n",
      "  18.556501    5.8549857   8.1570215   8.205889    6.5717936   6.6696277\n",
      "  -4.4197016 ]]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "image_size = 331\n",
    "base_model = keras.applications.NASNetLarge(\n",
    "    weights='imagenet',\n",
    "    input_shape=(image_size, image_size, 3),\n",
    "    include_top=False)\n",
    "inputs = keras.Input(shape=(image_size, image_size, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = keras.layers.Dense(13)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model('models/NASNetLarge.9306.h5')\n",
    "model.save('NASNetLarge')\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"NASNetLarge\") # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('NASNetLarge.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "    \n",
    "    \n",
    "for i in range(5):\n",
    "    index = np.random.randint(360)\n",
    "    print(f\"====TF Model result{index}====\")\n",
    "    print(model.predict(np.expand_dims(x_val[index],axis=0)))\n",
    "    print(y_val[index])\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_path=\"InceptionResNetV2.tflite\")\n",
    "    interpreter.allocate_tensors()\n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    # Test the model on random input data.\n",
    "    input_shape = input_details[0]['shape']\n",
    "\n",
    "    img = cv2.resize(x_val[index], (image_size,image_size)).astype('float32')\n",
    "\n",
    "    input_data = np.expand_dims(img, axis = 0)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # The function `get_tensor()` returns a copy of the tensor data.\n",
    "    # Use `tensor()` in order to get a pointer to the tensor.\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    print(\"====TFLite result====\")\n",
    "    print(output_data)\n",
    "    print(np.argmax(output_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('py37_tensorflow': conda)",
   "language": "python",
   "name": "python37764bitpy37tensorflowcondad3d0096e9a294093be1a32139e29a09f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
